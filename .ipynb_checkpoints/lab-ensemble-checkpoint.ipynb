{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB | Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the data**\n",
    "\n",
    "In this challenge, we will be working with the same Spaceship Titanic data, like the previous Lab. The data can be found here:\n",
    "\n",
    "https://raw.githubusercontent.com/data-bootcamp-v4/data/main/spaceship_titanic.csv\n",
    "\n",
    "Metadata\n",
    "\n",
    "https://github.com/data-bootcamp-v4/data/blob/main/spaceship_titanic.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Lab, you should try different ensemble methods in order to see if can obtain a better model than before. In order to do a fair comparison, you should perform the same feature scaling, engineering applied in previous Lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor,AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, root_mean_squared_error\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spaceship = pd.read_csv(\"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/spaceship_titanic.csv\")\n",
    "spaceship.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now perform the same as before:\n",
    "- Feature Scaling\n",
    "- Feature Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spaceship = spaceship.dropna()\n",
    "spaceship.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spaceship['Cabin'] = spaceship['Cabin'].apply(lambda x: x.split('/')[0] if isinstance(x, str) else np.nan)\n",
    "spaceship = spaceship.drop(columns=['Name'])\n",
    "spaceship = spaceship.drop(columns=['PassengerId'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spaceship = pd.get_dummies(spaceship, columns=['HomePlanet','CryoSleep','Cabin','Destination','VIP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spaceship_numerical = spaceship.select_dtypes(include=['number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spaceship_numerical_norm = normalizer.fit_transform(spaceship_numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spaceship_numerical_norm_df = pd.DataFrame(spaceship_numerical_norm, columns=spaceship_numerical.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = spaceship.select_dtypes(include=['number']).columns\n",
    "spaceship = spaceship.drop(columns=numerical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spaceship_combined = pd.concat([spaceship, spaceship_numerical_norm_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_cols = spaceship_combined.select_dtypes(include=['bool']).columns\n",
    "spaceship_combined[boolean_cols] = spaceship_combined[boolean_cols].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spaceship_combined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X-y split; features = X, target = y\n",
    "features = spaceship_combined.drop(columns = [\"Transported\"])\n",
    "target = spaceship_combined[\"Transported\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size = 0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Selection** - now you will try to apply different ensemble methods in order to get a better model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeRegressor(max_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_dt = tree.predict(X_test)\n",
    "print(f\"MAE, {mean_absolute_error(y_pred_test_dt, y_test): .2f}\")\n",
    "print(f\"MSE, {mean_squared_error(y_pred_test_dt, y_test): .2f}\")\n",
    "print(f\"RMSE, {root_mean_squared_error(y_pred_test_dt, y_test): .2f}\")\n",
    "print(f\"R2 score, {tree.score(X_test, y_test): .2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bagging and Pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_reg = BaggingClassifier(DecisionTreeClassifier(max_depth=20),\n",
    "                               n_estimators=100, # number of models to use\n",
    "                               max_samples = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_bag = bagging_reg.predict(X_test)\n",
    "\n",
    "print(f\"MAE {mean_absolute_error(y_pred_test_bag, y_test): .2f}\")\n",
    "print(f\"RMSE {root_mean_squared_error(y_pred_test_bag, y_test): .2f}\")\n",
    "print(f\"MSE {mean_squared_error(y_pred_test_bag, y_test): .2f}\")\n",
    "print(f\"R2 score {bagging_reg.score(X_test, y_test): .2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasting_reg = BaggingClassifier(DecisionTreeClassifier(max_depth=20), n_estimators=100,max_samples=1000,bootstrap=False) # For Pasting, set bootstrap to False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasting_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_past = pasting_reg.predict(X_test)\n",
    "\n",
    "print(f\"MAE {mean_absolute_error(y_pred_test_past, y_test): .2f}\")\n",
    "print(f\"RMSE {root_mean_squared_error(y_pred_test_past, y_test): .2f}\")\n",
    "print(f\"MSE {mean_squared_error(y_pred_test_past, y_test): .2f}\")\n",
    "print(f\"R2 score {pasting_reg.score(X_test, y_test): .2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestRegressor(n_estimators=100,\n",
    "                             max_depth=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_rf = forest.predict(X_test)\n",
    "print(f\"MAE {mean_absolute_error(y_pred_test_rf, y_test): .2f}\")\n",
    "print(f\"MSE, {mean_squared_error(y_pred_test_rf, y_test): .2f}\")\n",
    "print(f\"RMSE, {root_mean_squared_error(y_pred_test_rf, y_test): .2f}\")\n",
    "print(f\"R2 score, {forest.score(X_test, y_test): .2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_reg = GradientBoostingRegressor(max_depth=20,\n",
    "                                   n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_gb = gb_reg.predict(X_test)\n",
    "\n",
    "print(f\"MAE, {mean_absolute_error(y_pred_test_gb, y_test): .2f}\")\n",
    "print(f\"MSE, {mean_squared_error(y_pred_test_gb, y_test): .2f}\")\n",
    "print(f\"RMSE, {root_mean_squared_error(y_pred_test_gb, y_test): .2f}\")\n",
    "print(f\"R2 score, {gb_reg.score(X_test, y_test): .2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adaptive Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_reg = AdaBoostRegressor(DecisionTreeRegressor(max_depth=20),\n",
    "                            n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_ada = ada_reg.predict(X_test)\n",
    "\n",
    "print(f\"MAE, {mean_absolute_error(y_pred_test_ada, y_test): .2f}\")\n",
    "print(f\"MSE, {mean_squared_error(y_pred_test_ada, y_test): .2f}\")\n",
    "print(f\"RMSE, {root_mean_squared_error(y_pred_test_ada, y_test): .2f}\")\n",
    "print(f\"R2 score, {ada_reg.score(X_test, y_test): .2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which model is the best and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging and Pasting because predict 80% accuracy and has lowest MAE only 0.21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
